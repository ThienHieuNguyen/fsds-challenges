{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring overfitting and underfitting\n",
    "\n",
    "![](https://images.unsplash.com/photo-1532375810709-75b1da00537c?ixlib=rb-1.2.1&ixid=eyJhcHBfaWQiOjEyMDd9&auto=format&fit=crop&w=1055&q=80)\n",
    "\n",
    "## Context\n",
    "This dataset is originally from the National Institute of Diabetes and Digestive and Kidney Diseases. The objective of the dataset is to predict whether or not a patient has diabetes, based on certain diagnostic measurements included in the dataset. All patients here are females at least 21 years old of Pima Indian heritage.\n",
    "\n",
    "## Content\n",
    "The datasets consists of several medical predictor variables and one target variable, Outcome. Predictor variables includes the number of pregnancies the patient has had, their BMI, insulin level, age, and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-22T07:36:10.156718Z",
     "start_time": "2019-10-22T07:36:10.153694Z"
    }
   },
   "outputs": [],
   "source": [
    "# TODO : Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q1** : Load the data located in the `diabetes.csv` file in the `input` folder. Do a quick EDA on it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-22T07:36:53.059833Z",
     "start_time": "2019-10-22T07:36:53.056861Z"
    }
   },
   "outputs": [],
   "source": [
    "# TODO : load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-22T07:37:03.046907Z",
     "start_time": "2019-10-22T07:37:03.042756Z"
    }
   },
   "outputs": [],
   "source": [
    "# TODO : Explore data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-22T07:37:03.046907Z",
     "start_time": "2019-10-22T07:37:03.042756Z"
    }
   },
   "outputs": [],
   "source": [
    "# TODO : Explore data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-22T07:37:03.046907Z",
     "start_time": "2019-10-22T07:37:03.042756Z"
    }
   },
   "outputs": [],
   "source": [
    "# TODO : Explore data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-22T07:37:03.046907Z",
     "start_time": "2019-10-22T07:37:03.042756Z"
    }
   },
   "outputs": [],
   "source": [
    "# TODO : Explore data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q2** : Let's explore how the size of the train and the test set will affect the performance of the model.\n",
    "\n",
    "Do several splits of your data between train and test set. The test size should vary between 10% of the dataset and 90% of the dataset, in increments of 5% (e.g. first try a split with a test size of 0.10, then of 0.15, then of 0.20, then ..., then of 0.85, then of 0.90).\n",
    "\n",
    "Fit a KNN on each split of the data. Plot the evolution of the **accuracy score** of your model on both train and test sets depending on the proportion of test data in each split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-22T07:38:01.314342Z",
     "start_time": "2019-10-22T07:38:01.309452Z"
    }
   },
   "outputs": [],
   "source": [
    "# TODO : split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-22T07:43:24.142165Z",
     "start_time": "2019-10-22T07:43:24.139551Z"
    }
   },
   "outputs": [],
   "source": [
    "# TODO : fit KNN on each split of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-22T07:43:42.813881Z",
     "start_time": "2019-10-22T07:43:42.808551Z"
    }
   },
   "outputs": [],
   "source": [
    "# TODO : plot the accuracy on train and test set for each split of the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do you conclude ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q3** : Let's now explore how the value of `K` will affect the performance of the model. Using a split of 67% of training data and 33% of test data, fit several KNNs on the data with a `K` value varying between 1 and 50.\n",
    "\n",
    "Plot the evolution of the **accuracy score** depending on the value of K. You can also try plotting the **evolution of the model error** depending on the value of K (the classification error can be defined by 1 - the accuracy score)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-04T12:08:59.077335Z",
     "start_time": "2020-05-04T12:08:58.813120Z"
    }
   },
   "outputs": [],
   "source": [
    "# TODO : split data in 80% train set, 20% test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-22T07:48:07.319121Z",
     "start_time": "2019-10-22T07:48:07.314718Z"
    }
   },
   "outputs": [],
   "source": [
    "# TODO : fit KNN models with varying values of K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-22T07:49:08.089438Z",
     "start_time": "2019-10-22T07:49:08.084391Z"
    }
   },
   "outputs": [],
   "source": [
    "# Plot the accuracy score on train and on test for each value of K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the model error on train and on test for each value of K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q4** : Let's try to work with a Logistic Regression. Using the default hyperparameters of the Logistic Regression, compute the accuracy score on the train and the test set. What do you conclude, in terms of bias/variance ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO : compute accuracy scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q5.** Let's try adding some regularization to the Logistic Regression.\n",
    "Plot the evolution of the **accuracy score** depending on the value of C. You can also try plotting the **evolution of the model error** depending on the value of C (the classification error can be defined by 1 - the accuracy score)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO : fit Logistic Regression models with varying values of C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the accuracy score on train and on test for each value of C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the model error on train and on test for each value of C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q6.** Let's use a more complex model : the **support vector classifier**. Using the default hyperparameters of the SVC, compute the accuracy score on the train and the test set. What do you conclude, in terms of bias/variance ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-04T12:12:00.810027Z",
     "start_time": "2020-05-04T12:12:00.807324Z"
    }
   },
   "outputs": [],
   "source": [
    "# TODO : compute accuracy scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q7.** Let's try adding some regularization to the SVC.\n",
    "Plot the evolution of the **accuracy score** depending on the value of C. You can also try plotting the **evolution of the model error** depending on the value of C (the classification error can be defined by 1 - the accuracy score)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO : fit SVC models with varying values of C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the accuracy score on train and on test for each value of C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the model error on train and on test for each value of C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q8. \\[BONUS\\]** : check out the scikit-learn documentation about the `RandomForestClassifier`. Compute the accuracy score of this model (using the default hyperparameters) on the train and test sets. What do you conclude ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO : compute accuracy scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q9. \\[BONUS\\]** Let's try adding some regularization to the RandomForest. This type of model does not have a regalurization parameter per se, but you can reduce the model complexity by limiting the value of the hyperparameter `max_depth`.\n",
    "\n",
    "Plot the evolution of the **accuracy score** depending on the value of `max_depth`. You can try `max_depth` values between 1 and 50. \n",
    "You can also try plotting the **evolution of the model error** depending on the value of `max_depth` (the classification error can be defined by 1 - the accuracy score)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO : fit RFC models with varying values of max_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the accuracy score on train and on test for each value of max_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the model error on train and on test for each value of max_depth"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
