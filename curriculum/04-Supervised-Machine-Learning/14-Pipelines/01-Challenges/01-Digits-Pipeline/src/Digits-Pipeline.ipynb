{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge - Digits Pipeline\n",
    "\n",
    "![](https://images.unsplash.com/photo-1562343128-59e6fa1c7eb0?ixlib=rb-1.2.1&ixid=eyJhcHBfaWQiOjEyMDd9&auto=format&fit=crop&w=1126&q=80)\n",
    "\n",
    "In this exercise, you will build Pipelines on a simple dataset, the MNIST dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q1**: Load the **digits dataset** from sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-29T10:38:39.010296Z",
     "start_time": "2019-10-29T10:38:38.998369Z"
    }
   },
   "outputs": [],
   "source": [
    "# TODO : imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q2**: As usual, have a quick look at the data. How many classes are there ? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-29T19:51:30.706142Z",
     "start_time": "2019-10-29T19:51:30.701505Z"
    }
   },
   "outputs": [],
   "source": [
    "# TODO : Explore the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-29T19:51:30.706142Z",
     "start_time": "2019-10-29T19:51:30.701505Z"
    }
   },
   "outputs": [],
   "source": [
    "# TODO : Explore the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q3**: Which preprocessing steps should you take before fitting a ML model on the data ? Build a preprocessing pipeline that allows you to do all those steps in an easy manner. Don't forget to split your dataset before fitting the pipeline on it !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-29T10:36:27.231673Z",
     "start_time": "2019-10-29T10:36:27.223734Z"
    }
   },
   "outputs": [],
   "source": [
    "# TODO : Which steps should you take ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-29T10:36:34.662159Z",
     "start_time": "2019-10-29T10:36:34.655216Z"
    }
   },
   "outputs": [],
   "source": [
    "# TODO : Don't forget to split your dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-29T10:37:17.960075Z",
     "start_time": "2019-10-29T10:37:17.954823Z"
    }
   },
   "outputs": [],
   "source": [
    "# TODO : Build preprocessing pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-29T10:37:18.572026Z",
     "start_time": "2019-10-29T10:37:18.565922Z"
    }
   },
   "outputs": [],
   "source": [
    "# TODO : Build preprocessing pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q4**: Add a `LogisticRegression` to your pipeline, fit it on the data, and make a prediction on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-29T10:37:20.900183Z",
     "start_time": "2019-10-29T10:37:20.896737Z"
    }
   },
   "outputs": [],
   "source": [
    "# TODO : Classify data with a `LogisticRegression`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-29T10:37:21.634080Z",
     "start_time": "2019-10-29T10:37:21.389751Z"
    }
   },
   "outputs": [],
   "source": [
    "# TODO : Classify data with a `LogisticRegression`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO : accuracy score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-29T10:37:22.230056Z",
     "start_time": "2019-10-29T10:37:22.215111Z"
    }
   },
   "outputs": [],
   "source": [
    "# TODO : classification report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q5** : Run hyperparameters optimization on your model, on both the preprocessing steps and the classification model itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-29T08:35:50.215642Z",
     "start_time": "2019-10-29T08:35:50.209764Z"
    }
   },
   "outputs": [],
   "source": [
    "# TODO : hyperparameters optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-29T08:36:05.504043Z",
     "start_time": "2019-10-29T08:35:51.741811Z"
    }
   },
   "outputs": [],
   "source": [
    "# TODO : hyperparameters optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-29T08:36:09.434164Z",
     "start_time": "2019-10-29T08:36:09.423475Z"
    }
   },
   "outputs": [],
   "source": [
    "# TODO : hyperparameters optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q6**: Let's try to find a better model to predict the digits. Using your previously built pipeline, loop through the different classification models that you know and find the best model for this specific task !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-29T08:35:07.510403Z",
     "start_time": "2019-10-29T08:35:06.629036Z"
    }
   },
   "outputs": [],
   "source": [
    "# TODO : model selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "âš ï¸ This process is know as **model selection**. Please keep in mind that running through all possible models would be extremely time- and resource-consuming. Your job, as a data scientist, is to operate a pre-selection of models using your own theorical and practical knowledge, before testing them empirically."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q7**: What if I told you that you can actually use the models themselves as hyperparameters **in** your pipeline ? Explore the scikit-learn [documentation](https://scikit-learn.org/stable/modules/compose.html) on [pipelines](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html#sklearn.pipeline.Pipeline) to find out how to do that, and find the best possible combination of steps in your pipeline.\n",
    "\n",
    "> ðŸ”¦ **Hint** : Run a `GridSearchCV` on a pipeline that can:\n",
    "- Apply a `StandardScaler`, or a `MinMaxScaler`, or no scaler at all;\n",
    "- Apply a `PCA` with optimization of the `n_components` hyperparameter;\n",
    "- Apply a `SVC` or a `LogisticRegression`, with optimization of the `C` parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-29T10:37:41.090995Z",
     "start_time": "2019-10-29T10:37:41.086290Z"
    }
   },
   "outputs": [],
   "source": [
    "# TODO : Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-29T10:40:58.805777Z",
     "start_time": "2019-10-29T10:40:58.798441Z"
    }
   },
   "outputs": [],
   "source": [
    "# TODO : Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-29T10:40:58.805777Z",
     "start_time": "2019-10-29T10:40:58.798441Z"
    }
   },
   "outputs": [],
   "source": [
    "# TODO : Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-29T10:41:26.206182Z",
     "start_time": "2019-10-29T10:41:26.188329Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# TODO : Run the optimized model on the test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**BONUS** : Try to improve your score even more by optimizing your model selection using pipelines !"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
