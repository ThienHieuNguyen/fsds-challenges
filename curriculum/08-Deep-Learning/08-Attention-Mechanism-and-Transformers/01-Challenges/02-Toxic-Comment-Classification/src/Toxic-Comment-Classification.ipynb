{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge - Jigsaw Unintended Bias in Toxicity Classification\n",
    "\n",
    "![](https://images.unsplash.com/photo-1581686051110-30d45d3e1fd8?ixlib=rb-1.2.1&ixid=eyJhcHBfaWQiOjEyMDd9&auto=format&fit=crop&w=1050&q=80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "X1y2tEJrd79K"
   },
   "source": [
    "⚠️ **Transformers are huge models and in order to train / fine-tune such models you need a GPU. Therefore you will need to run this notebook on Colab.**\n",
    "\n",
    "⚠️ **Please upload this notebook on Colab.**\n",
    "\n",
    "⚠️ **Do no forget to use GPU as hardware accelerator. To do that go to `Edit -> Notebook Settings` and select GPU at the field `Hardware Accelerator`**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_RFVHfX0dKJ4"
   },
   "source": [
    "Let's select the Tensorflow 2.0 version to run this Colab notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BhOFlJ8ldLn5"
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "# Install TensorFlow\n",
    "try:\n",
    "  # %tensorflow_version only exists in Colab.\n",
    "  %tensorflow_version 2.x\n",
    "except Exception:\n",
    "  pass\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FWSIuoEO9Xks"
   },
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9fcuZr4Yd6qP"
   },
   "source": [
    "This challenge is based on an interesting Kaggle Competition: the [Jigsaw Toxic Comment Clasffication Challenge](https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge).\n",
    "\n",
    "\n",
    "The main goal of the exercise is to predict toxicity of comments.\n",
    "\n",
    "You are provided with a large number of Wikipedia comments which have been labeled by human raters for toxic behavior. There are 6 types of toxicity:\n",
    "- toxic\n",
    "- severe_toxic\n",
    "- obscene\n",
    "- threat\n",
    "- insult\n",
    "- identity_hate\n",
    "\n",
    "Each comment has a label for each one of the categories. A label equals to 1 means that comment is considered toxic in that category.\n",
    "\n",
    "Given the memory needs for training / fine-tuning a Transformer, you will be using only one of these categories as target. Feel free to chose one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TJ-OtUhS9VyG"
   },
   "source": [
    "## Downloading Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XKCPBT_c-P70"
   },
   "source": [
    "In order to use the data available for this competion by kaggle on Colab you need to follow the steps below:\n",
    "1. Make sure you have a Kaggle account (you can subscribe using your Google Account for example)\n",
    "2. Go to `My Account` \n",
    "3. At Section API click on `Create New API Token`. A `json` file will be automatically downloaded\n",
    "4. Open the `json` file and substitute the username and key in the cell below by the data provided on the file \n",
    "5. Run the cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fEXLkIkabFl5"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['KAGGLE_USERNAME'] = \"your_username\"\n",
    "os.environ['KAGGLE_KEY'] = \"your_kaggle_key\"\n",
    "\n",
    "!pip install -q kaggle\n",
    "!pip install -q kaggle-cli\n",
    "\n",
    "!kaggle competitions download -c jigsaw-toxic-comment-classification-challenge\n",
    "!unzip train.csv.zip\n",
    "!unzip test.csv.zip\n",
    "!unzip test_labels.csv.zip\n",
    "\n",
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cLv1oUT1_8hB"
   },
   "source": [
    "## Loading data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OcCM-LxYEiEL"
   },
   "source": [
    "As usual, load the training data using pandas (file `train.csv`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-10T12:57:47.381064Z",
     "start_time": "2020-03-10T12:57:47.377916Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "VQ7uRgQQZRzt"
   },
   "outputs": [],
   "source": [
    "# ENTER YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oXBgKb3hZRz3"
   },
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_m8yUZIDEwvP"
   },
   "source": [
    "Now we are going to prepare the data before training our model.\n",
    "\n",
    "Choose one category as your target.\n",
    "\n",
    "Also select the `comment_text` column to a variable `comments` so that we can process it using Transformers tokenizers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-10T07:38:19.506097Z",
     "start_time": "2020-03-10T07:38:19.172040Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "2xy5J_vWZRz4"
   },
   "outputs": [],
   "source": [
    "CATEGORY = # ENTER YOUR CODE HERE\n",
    "\n",
    "targets = # ENTER YOUR CODE HERE\n",
    "comments = # ENTER YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_wZWl6GiFNH3"
   },
   "source": [
    "Decide a transformer model you want to use (eg: DistilBert, Bert, etc) and import its correspondent tokenizer.\n",
    "\n",
    "Use the method `.from_pretrained` to load the tokenizer.\n",
    "\n",
    "You can refer to the lecture to see how you do it.\n",
    "\n",
    "You can see the list of pretrained transformers models available here: https://huggingface.co/transformers/pretrained_models.html\n",
    "\n",
    "> *As an advice, for this exercise, prefer to use a version of DistilBert, as it is smaller and takes less time to train than the majority of Transformers*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-10T07:38:55.745224Z",
     "start_time": "2020-03-10T07:38:36.607992Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "gSpukftdZRz8"
   },
   "outputs": [],
   "source": [
    "from transformers import # ENTER YOUR CODE HERE\n",
    "\n",
    "tokenizer = # ENTER YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MDtWhfhsF9lq"
   },
   "source": [
    "Complete the function `process_comments` below in order to process the text and encode it in a fashion that it can be used be your Transformer model.\n",
    "\n",
    "As you are padding the sentences, do not forget to store the attention mask, as we saw during the lecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-10T07:39:12.522669Z",
     "start_time": "2020-03-10T07:39:12.516410Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "EOyA_PvbZR0B"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def process_comments(tokenizer, comments, max_length):\n",
    "    input_ids, attention_mask = [], []\n",
    "    for comment in tqdm(comments):\n",
    "        \n",
    "        # ENTER YOUR CODE HERE\n",
    "        \n",
    "    return input_ids, attention_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RNs7ynxFG_BF"
   },
   "source": [
    "Choose a max length for your sentences and generate all input ids and the attention mask:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-03-10T07:39:34.051Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "W5dcG9K0ZR0H",
    "outputId": "250fb480-c7f5-4a24-d746-7511214f97bb"
   },
   "outputs": [],
   "source": [
    "MAX_LENGTH = # ENTER YOUR CODE HERE\n",
    "\n",
    "input_ids, attention_mask = # ENTER YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "m1v2p2Mvln3C"
   },
   "source": [
    "Using the `train_test_split` method from sci-kit learn, build a training set and a evaluation set. Feel free to choose the size of the evaluation set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WBDdTXveZR0V"
   },
   "outputs": [],
   "source": [
    "# ENTER YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RBL5ZWtrmyDW"
   },
   "source": [
    "Using the method `tf.data.Dataset.from_tensor_slices`, build the training and validation `tf.Datasets`.\n",
    "\n",
    "You will need to feed this method with the inputs ids, the attention mask and the train targets.\n",
    "> *Hint: use a dictionnaire to feed both input ids and attention mask*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "o-QOTqexnUdC"
   },
   "outputs": [],
   "source": [
    "train_dataset = # ENTER YOUR CODE HERE\n",
    "val_dataset = # ENTER YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vhhSJzNCoICf"
   },
   "source": [
    "Now shuffle and batch the datasets (you can refer to [Tensorflow documentation](https://www.tensorflow.org/tutorials/load_data/numpy)):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MbfD0zbcn9gs"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = # ENTER YOUR CODE HERE\n",
    "SHUFFLE_BUFFER_SIZE = # ENTER YOUR CODE HERE\n",
    "\n",
    "train_dataset = # ENTER YOUR CODE HERE\n",
    "val_dataset = # ENTER YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "j_ASmcf3nk3l"
   },
   "source": [
    "## Modelling and training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZpwzkOmIdIUY"
   },
   "source": [
    "Now that you have your data well prepared, import and build a pretrained Transformer model from the `transformers` library.\n",
    "\n",
    "Please be sure that you are using a model for `SequenceClassification` as our task here is basically the creation of a classifier that detects toxicities in sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "b_iaWrx-3tef"
   },
   "outputs": [],
   "source": [
    "from transformers import # ENTER YOUR CODE HERE\n",
    "\n",
    "model = # ENTER YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PwGZ3l_5ftT5"
   },
   "source": [
    "Now, as usual, define the optimizer, the loss and the metrics that will be used during training and compile the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WqDncYScn160"
   },
   "outputs": [],
   "source": [
    "# ENTER YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WEfqTh8Uf84z"
   },
   "source": [
    "Now let's train our transformer!\n",
    "\n",
    "> *Obs: It will take about 30min for each epoch during the training, therefore you can launch the training for just very few epochs and go take a coffee or you can start taking a look at the challenge 02.*\n",
    "\n",
    "> *Optional: Use an `early_stopping` callback to avoid overfitting during training*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "colab_type": "code",
    "id": "u13d9BdwqYiU",
    "outputId": "26cf189f-b07d-4c30-9266-671b731cb185",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ENTER YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iu7lnTdsMcNc"
   },
   "source": [
    "## Computing predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wM9-BC3_qqP5"
   },
   "source": [
    "Now that you trained the your model, let's load the test samples and evaluate the model on it.\n",
    "\n",
    "Load the test data and test labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "rTxOuYqDNO08",
    "outputId": "4365d4e2-80ed-45e4-bd59-a061caf5af66"
   },
   "outputs": [],
   "source": [
    "test_data = # ENTER YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "MVuQ6FZdNGQS",
    "outputId": "9e4d4808-2487-408e-a401-f21c0b624b66"
   },
   "outputs": [],
   "source": [
    "test_labels = # ENTER YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KU-OXrksNohW"
   },
   "source": [
    "Process the test comments as we proceeded with the training data and select the category you used to train your model.\n",
    "\n",
    "**Please be sure you eliminate the rows with labels == -1, these rows should not be used for evaluation.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JhqHdiL_NqeX"
   },
   "outputs": [],
   "source": [
    "# Select the targets and comments with labels != -1\n",
    "test_targets = # ENTER YOUR CODE HERE\n",
    "test_comments = # ENTER YOUR CODE HERE\n",
    "\n",
    "# Process the comments\n",
    "test_inputs, test_mask = # ENTER YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IZUaCfAnaFL8"
   },
   "source": [
    "Now compute the predictions from your model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "E9nJHufzaNFi"
   },
   "outputs": [],
   "source": [
    "predictions = # ENTER YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "A-Ee68akPM3E"
   },
   "source": [
    "You can see that the predictions (the Transformer's output) are a 2-dim vector with values from  `-inf` to `inf`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "RATdKmDLZQ_G",
    "outputId": "d9b2532c-04ce-4eb8-f9c5-10f894691d14"
   },
   "outputs": [],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fnwmX3AXaf5A"
   },
   "source": [
    "These values correspond to the logits that are outputted from the model.\n",
    "\n",
    "In order to compute the probability of label == 1 we should use the softmax function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "ArPDjjzHYFiu",
    "outputId": "b3dac911-7088-420d-b2af-b3dbe8185c96"
   },
   "outputs": [],
   "source": [
    "from scipy.special import softmax\n",
    "\n",
    "probas = softmax(predictions, axis=1)\n",
    "\n",
    "probas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Bm-ssGajbG7E"
   },
   "source": [
    "We can notice that the classes are very unbalanced (there are much less toxic comments than non toxic comments):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "oiTqMXLpbebb",
    "outputId": "47e71a9f-a9ef-444f-fe9d-713ccb984412"
   },
   "outputs": [],
   "source": [
    "n_toxic = sum(probas[:,1] > 0.5)\n",
    "n_non_toxic = sum(probas[:,0] > 0.5)\n",
    "\n",
    "print(\"Proportion of toxic comments: {0:.2%}\".format(n_toxic/(n_toxic + n_non_toxic)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "F__57JROcI7v"
   },
   "source": [
    "Therefore, in order to evaluate properly our model, we should be using a metric that takes this unbalaceness into account. The AUC score is one of these metrics, and it is the one used to evaluate the performance of the competitors in the original Kaggle competition.\n",
    "\n",
    "Import the `roc_auc_score` function for the scikit-learn library and use it to evaluate your predictions.\n",
    "\n",
    "Please be sure you use the probability of label == 1 computed by your model as input to the `roc_auc_score` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "ukMAh1F1YSdb",
    "outputId": "2af59462-3fa8-4161-a5e1-3307d16fe654"
   },
   "outputs": [],
   "source": [
    "# ENTER YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yjxykGLddP3o"
   },
   "source": [
    "## (Optional) Do the same for other classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8dabfv_0dnRL"
   },
   "source": [
    "As a optional exercise, you can repeat the same steps and train other transformer models for the other 5 categories.\n",
    "\n",
    "It will take some time, but after doing it, you can submit your predictions to the official competition and check your potential ranking! "
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "01-Toxic Comment Classification Challenge - Solution.ipynb",
   "provenance": []
  },
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
