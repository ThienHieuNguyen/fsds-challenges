{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge - Graph Convolution Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://images.unsplash.com/photo-1503365070998-37e56a2606e2?ixlib=rb-1.2.1&ixid=eyJhcHBfaWQiOjEyMDd9&auto=format&fit=crop&w=1050&q=80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the exercise below, you will be asked to play around with the official implementation of Graph Convolutional Network (GCN). The code has been adapted so that you are able to run it in the Juypter notebook directly, and not through command lines. \n",
    "\n",
    "In this example, you will:\n",
    "- load a graph\n",
    "- try to make predictions through classical MLP\n",
    "- try to make predictions through GCNs \n",
    "- observe the results\n",
    "- read the code of the implementation\n",
    "- fine-tune the parameters\n",
    "- repeat it for other networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!! It is required to have Tensorflow 2.0 for this exercicse !!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-19T18:03:34.800235Z",
     "start_time": "2020-06-19T18:03:25.753264Z"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import tensorflow.compat.v1 as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from gcn.utils import *\n",
    "from gcn.models import GCN, MLP\n",
    "\n",
    "tf.disable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-19T18:04:49.271858Z",
     "start_time": "2020-06-19T18:04:49.254399Z"
    }
   },
   "outputs": [],
   "source": [
    "# Set random seed\n",
    "seed = 123\n",
    "np.random.seed(seed)\n",
    "tf.set_random_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-19T18:04:53.425657Z",
     "start_time": "2020-06-19T18:04:53.420207Z"
    }
   },
   "outputs": [],
   "source": [
    "# Constants\n",
    "DATASET = \"cora\" # Dataset string.\n",
    "LR = 0.01 # Initial learning rate.\n",
    "HIDDEN_1 = 16 # Number of units in hidden layer 1.\n",
    "EPOCHS = 200 # Number of epochs to train.\n",
    "DROPOUT = 0.5 # Dropout rate (1 - keep probability).\n",
    "WEIGHT_DECAY = 5e-4 # Weight for L2 loss on embedding matrix.\n",
    "EARLY_STOPPING = 10 # Tolerance for early stopping (# of epochs)\n",
    "MAX_DEGREE = 3 # Maximum Chebyshev polynomial degree.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q1** : The code below will load the graph which has previously been saved as a Pickle object. Take the \"graph\" variable and plot it using NetowrkX. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The different extensions here are pre-processing of the graph. They correspond to:\n",
    "- x => the feature vectors of the training instances as scipy.sparse.csr.csr_matrix object;\n",
    "- tx => the feature vectors of the test instances as scipy.sparse.csr.csr_matrix object;\n",
    "- allx => the feature vectors of both labeled and unlabeled training instances (a superset of ind.dataset_str.x) as scipy.sparse.csr.csr_matrix object;\n",
    "- y => the one-hot labels of the labeled training instances as numpy.ndarray object;\n",
    "- ty => the one-hot labels of the test instances as numpy.ndarray object;\n",
    "- ally => the labels for instances in ind.dataset_str.allx as numpy.ndarray object;\n",
    "- graph => a dict in the format {index: [index_of_neighbor_nodes]} as collections.defaultdict object;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-19T18:05:14.441759Z",
     "start_time": "2020-06-19T18:05:14.420194Z"
    }
   },
   "outputs": [],
   "source": [
    "names = ['x', 'y', 'tx', 'ty', 'allx', 'ally', 'graph']\n",
    "objects = []\n",
    "for i in range(len(names)):\n",
    "    with open(\"gcn/data/ind.cora.{}\".format(names[i]), 'rb') as f:\n",
    "        if sys.version_info > (3, 0):\n",
    "            objects.append(pkl.load(f, encoding='latin1'))\n",
    "        else:\n",
    "            objects.append(pkl.load(f))\n",
    "\n",
    "x, y, tx, ty, allx, ally, graph = tuple(objects)\n",
    "test_idx_reorder = parse_index_file(\"gcn/data/ind.cora.test.index\")\n",
    "test_idx_range = np.sort(test_idx_reorder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the object `graph` using networkx."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-19T18:09:45.224229Z",
     "start_time": "2020-06-19T18:09:45.219956Z"
    }
   },
   "outputs": [],
   "source": [
    "# TODO : plot the graph with networkx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q2** : To learn more about the dataset, you can check this link: https://relational.fit.cvut.cz/dataset/CORA. We will be using the CORA citation network. The network is directed. Nodes represent scientific papers. An edge between two nodes indicates that the left node cites the right node."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q3**: What is the shape of the training feature vector? And of the test feature vector? What do the features represent? Comment on the ratio of training and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-19T18:10:21.029525Z",
     "start_time": "2020-06-19T18:10:21.025782Z"
    }
   },
   "outputs": [],
   "source": [
    "# TODO : what is the shape of `x` ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-19T18:10:19.349575Z",
     "start_time": "2020-06-19T18:10:19.343903Z"
    }
   },
   "outputs": [],
   "source": [
    "# TODO : what is the shape of `tx` ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 140 training data, and 1000 test ones. The features correspond to individual words present in the vocabulary (1 or 0). Since there is 7 times more testing than training data, this is a typical semi-supervised learning problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q4**: What is the shape of the labels?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-19T18:10:47.055372Z",
     "start_time": "2020-06-19T18:10:47.052297Z"
    }
   },
   "outputs": [],
   "source": [
    "# TODO : What is the shape of `y` ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II. Multi-layer Perceptron approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q5**: You will now use the pre-built functions for the Multi-layer Perceptron. Read the code, and check the source code that is given within the `gcn` folder. Feel free to comment the code, and change the basic parameters defined above. The code below will: load the data, process it, define the model, the evaluation function, and initialize the session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-19T18:06:18.152765Z",
     "start_time": "2020-06-19T18:06:17.862400Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load data\n",
    "adj, features, y_train, y_val, y_test, train_mask, val_mask, test_mask = load_data(DATASET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-19T18:06:20.268453Z",
     "start_time": "2020-06-19T18:06:20.197999Z"
    }
   },
   "outputs": [],
   "source": [
    "features = preprocess_features(features)\n",
    "support = [preprocess_adj(adj)]\n",
    "num_supports = 1\n",
    "model_func = MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-19T18:06:26.589022Z",
     "start_time": "2020-06-19T18:06:26.062294Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define placeholders\n",
    "placeholders = {\n",
    "    'support': [tf.sparse_placeholder(tf.float32) for _ in range(num_supports)],\n",
    "    'features': tf.sparse_placeholder(tf.float32, shape=tf.constant(features[2], dtype=tf.int64)),\n",
    "    'labels': tf.placeholder(tf.float32, shape=(None, y_train.shape[1])),\n",
    "    'labels_mask': tf.placeholder(tf.int32),\n",
    "    'dropout': tf.placeholder_with_default(0., shape=()),\n",
    "    'num_features_nonzero': tf.placeholder(tf.int32)  # helper variable for sparse dropout\n",
    "}\n",
    "\n",
    "# Create model\n",
    "model = model_func(placeholders, LR, HIDDEN_1, WEIGHT_DECAY, input_dim=features[2][1], logging=True)\n",
    "\n",
    "# Initialize session\n",
    "sess = tf.Session()\n",
    "\n",
    "# Define model evaluation function\n",
    "def evaluate(features, support, labels, mask, placeholders):\n",
    "    t_test = time.time()\n",
    "    feed_dict_val = construct_feed_dict(features, support, labels, mask, placeholders)\n",
    "    outs_val = sess.run([model.loss, model.accuracy], feed_dict=feed_dict_val)\n",
    "    return outs_val[0], outs_val[1], (time.time() - t_test)\n",
    "\n",
    "# Init variables\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "cost_val = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q6**: The code below will run the model training. Try to understand it. Then, plot the results stored in the lists `plot_acc` and `plot_val_acc`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-19T18:06:44.388550Z",
     "start_time": "2020-06-19T18:06:40.910067Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_val_acc = []\n",
    "plot_acc = []\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "\n",
    "    t = time.time()\n",
    "    # Construct feed dictionary\n",
    "    feed_dict = construct_feed_dict(features, support, y_train, train_mask, placeholders)\n",
    "    feed_dict.update({placeholders['dropout']: DROPOUT})\n",
    "\n",
    "    # Training step\n",
    "    outs = sess.run([model.opt_op, model.loss, model.accuracy], feed_dict=feed_dict)\n",
    "\n",
    "    # Validation\n",
    "    cost, acc, duration = evaluate(features, support, y_val, val_mask, placeholders)\n",
    "    cost_val.append(cost)\n",
    "    \n",
    "    plot_val_acc.append(acc)\n",
    "    plot_acc.append(outs[2])\n",
    "    \n",
    "    # Print results\n",
    "    print(\"Epoch:\", '%04d' % (epoch + 1), \"train_loss=\", \"{:.5f}\".format(outs[1]),\n",
    "          \"train_acc=\", \"{:.5f}\".format(outs[2]), \"val_loss=\", \"{:.5f}\".format(cost),\n",
    "          \"val_acc=\", \"{:.5f}\".format(acc), \"time=\", \"{:.5f}\".format(time.time() - t))\n",
    "\n",
    "    if epoch > EARLY_STOPPING and cost_val[-1] > np.mean(cost_val[-(EARLY_STOPPING+1):-1]):\n",
    "        print(\"Early stopping...\")\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-19T18:12:14.887598Z",
     "start_time": "2020-06-19T18:12:14.885172Z"
    }
   },
   "outputs": [],
   "source": [
    "# TODO : plot the accuracy on the train test and on the validation test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q7**: What do you notice?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a large overfitting after only 6-8 epochs. Overall, the performance for node classification is test is really limited."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q8**: The code below will run for you an evaluation of the MLP, and give you the performance on the y_test that was set aside."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-19T18:07:07.391258Z",
     "start_time": "2020-06-19T18:07:07.368126Z"
    }
   },
   "outputs": [],
   "source": [
    "test_cost, test_acc, test_duration = evaluate(features, support, y_test, test_mask, placeholders)\n",
    "print(\"Test set results:\", \"cost=\", \"{:.5f}\".format(test_cost),\n",
    "      \"accuracy=\", \"{:.5f}\".format(test_acc), \"time=\", \"{:.5f}\".format(test_duration))\n",
    "\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# III. Graph Convolutional Network Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q9**: Now, as previously, you will be asked to run the code below, try to understand it, look at the source code and comment it if you want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-19T18:07:19.736962Z",
     "start_time": "2020-06-19T18:07:19.724089Z"
    }
   },
   "outputs": [],
   "source": [
    "support = [preprocess_adj(adj)]\n",
    "num_supports = 1\n",
    "model_func = GCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-19T18:07:22.022701Z",
     "start_time": "2020-06-19T18:07:21.716986Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define placeholders\n",
    "placeholders = {\n",
    "    'support': [tf.sparse_placeholder(tf.float32) for _ in range(num_supports)],\n",
    "    'features': tf.sparse_placeholder(tf.float32, shape=tf.constant(features[2], dtype=tf.int64)),\n",
    "    'labels': tf.placeholder(tf.float32, shape=(None, y_train.shape[1])),\n",
    "    'labels_mask': tf.placeholder(tf.int32),\n",
    "    'dropout': tf.placeholder_with_default(0., shape=()),\n",
    "    'num_features_nonzero': tf.placeholder(tf.int32)  # helper variable for sparse dropout\n",
    "}\n",
    "\n",
    "# Create model\n",
    "model = model_func(placeholders, LR, HIDDEN_1, WEIGHT_DECAY, input_dim=features[2][1], logging=True)\n",
    "\n",
    "# Initialize session\n",
    "sess = tf.Session()\n",
    "\n",
    "\n",
    "# Define model evaluation function\n",
    "def evaluate(features, support, labels, mask, placeholders):\n",
    "    t_test = time.time()\n",
    "    feed_dict_val = construct_feed_dict(features, support, labels, mask, placeholders)\n",
    "    outs_val = sess.run([model.loss, model.accuracy], feed_dict=feed_dict_val)\n",
    "    return outs_val[0], outs_val[1], (time.time() - t_test)\n",
    "\n",
    "\n",
    "# Init variables\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "cost_val = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q9**: The code below will run the model training. Try to understand it. Then, plot the results stored in the lists `plot_acc` and `plot_val_acc`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-19T18:07:33.107541Z",
     "start_time": "2020-06-19T18:07:29.403806Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_val_acc = []\n",
    "plot_acc = []\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "\n",
    "    t = time.time()\n",
    "    # Construct feed dictionary\n",
    "    feed_dict = construct_feed_dict(features, support, y_train, train_mask, placeholders)\n",
    "    feed_dict.update({placeholders['dropout']: DROPOUT})\n",
    "\n",
    "    # Training step\n",
    "    outs = sess.run([model.opt_op, model.loss, model.accuracy], feed_dict=feed_dict)\n",
    "\n",
    "    # Validation\n",
    "    cost, acc, duration = evaluate(features, support, y_val, val_mask, placeholders)\n",
    "    cost_val.append(cost)\n",
    "    \n",
    "    plot_val_acc.append(acc)\n",
    "    plot_acc.append(outs[2])\n",
    "    \n",
    "    # Print results\n",
    "    print(\"Epoch:\", '%04d' % (epoch + 1), \"train_loss=\", \"{:.5f}\".format(outs[1]),\n",
    "          \"train_acc=\", \"{:.5f}\".format(outs[2]), \"val_loss=\", \"{:.5f}\".format(cost),\n",
    "          \"val_acc=\", \"{:.5f}\".format(acc), \"time=\", \"{:.5f}\".format(time.time() - t))\n",
    "\n",
    "    if epoch > EARLY_STOPPING and cost_val[-1] > np.mean(cost_val[-(EARLY_STOPPING+1):-1]):\n",
    "        print(\"Early stopping...\")\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-19T18:13:04.670169Z",
     "start_time": "2020-06-19T18:13:04.665908Z"
    }
   },
   "outputs": [],
   "source": [
    "# TODO : plot the accuracy on the train test and on the validation test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q11**: What do you notice?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although there is also a slight overfitting, the overall model performance seems much better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q12**: The code below will run for you an evaluation of the MLP, and give you the performance on the y_test that was set aside."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-19T18:07:40.951684Z",
     "start_time": "2020-06-19T18:07:40.935028Z"
    }
   },
   "outputs": [],
   "source": [
    "test_cost, test_acc, test_duration = evaluate(features, support, y_test, test_mask, placeholders)\n",
    "print(\"Test set results:\", \"cost=\", \"{:.5f}\".format(test_cost),\n",
    "      \"accuracy=\", \"{:.5f}\".format(test_acc), \"time=\", \"{:.5f}\".format(test_duration))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Through this example, we demonstrated how much taking network structure into account during the training can be important, and improve the model performance by close to 25%."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
