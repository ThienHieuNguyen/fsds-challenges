{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge - Forward Propagation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://images.unsplash.com/photo-1478796415026-3c85ee65975e?ixlib=rb-1.2.1&ixid=eyJhcHBfaWQiOjEyMDd9&auto=format&fit=crop&w=1050&q=80)\n",
    "Photo by [Gaelle Marcel](https://unsplash.com/photos/gIj7RJPAkJA)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise you will implement your own forward propagation of a neural network, using Python and numpy only."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We consider again our example of neural network in the lectures:\n",
    "![](../../../00-Lectures/images/MLP_with_activations.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Begin by defining a numpy array `X` with 3 random values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: define X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now redefine the sigmoid function, which will be our activation function in our neural network.\n",
    "\n",
    "Reminder:\n",
    "$$\n",
    "sigmoid(x) = \\frac{1}{1 + e^{- x}} \n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Define the sigmoid function as g(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see on the plot, $a^{[1]}_1$ is computed with the values $x_1$, $x_2$ and $x_3$ as well as the associated weights $W^{[1]}_{1}$ and $b^{[1]}_{1}$:\n",
    "\n",
    "$$\n",
    "a^{[1]}_{1} = g(W^{[1]}_{1} \\times X + b^{[1]}_{1})\n",
    "$$\n",
    "\n",
    "Begin by defining randomly $W^{[1]}_{1}$ (which is a numpy array of three values) and $b^{[1]}_{1}$ and then compute $a^{[1]}_{1}$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Compute the activation of the first unit of the first layer a11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now do the same for the two other units of the first layer: compute $a^{[1]}_2$, $a^{[1]}_3$ and $a^{[1]}_4$ as `a12`, `a13` and `a14`.\n",
    "\n",
    "Reminder:\n",
    "\n",
    "$$\n",
    "a^{[1]}_{2} = g(W^{[1]}_{2} \\times X + b^{[1]}_{2})\n",
    "$$\n",
    "\n",
    "$$\n",
    "a^{[1]}_{3} = g(W^{[1]}_{3} \\times X + b^{[1]}_{3})\n",
    "$$\n",
    "\n",
    "$$\n",
    "a^{[1]}_{4} = g(W^{[1]}_{4} \\times X + b^{[1]}_{4})\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: compute a12, a13 and a14"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to transform our values $a^{[1]}_i$ (saved into `a11`, `a12`, `a13` and `a14` into a single vector of 4 values `a1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: compute a1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first layer is computed, now let's continue, we want to compute the values of the second layer, using the following formulas, still defining random values for weights and bias:\n",
    "\n",
    "$$\n",
    "a^{[2]}_{1} = g( W^{[2]}_{1} \\times a^{[1]} + b^{[2]}_{1})\n",
    "$$\n",
    "\n",
    "$$\n",
    "a^{[2]}_{2} = g(W^{[2]}_{2} \\times a^{[1]} + b^{[2]}_{2})\n",
    "$$\n",
    "\n",
    "$$\n",
    "a^{[2]}_{3} = g(W^{[2]}_{3} \\times a^{[1]} + b^{[2]}_{3})\n",
    "$$\n",
    "\n",
    "$$\n",
    "a^{[2]}_{4} = g(W^{[2]}_{4} \\times a^{[1]} + b^{[2]}_{4})\n",
    "$$\n",
    "\n",
    "Be careful, now the weights $W^{[2]}_i$ might not have the same dimension..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: compute a21, a22, a23, a24"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, compute the vector `a2`, concatenation of `a21`, `a22`, `a23` and `a24`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: compute a2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, compute the output value `a3` using the following formula:\n",
    "\n",
    "$$\n",
    "a^{[3]}_{1} = g(W^{[3]}_{1} \\times a^{[2]} + b^{[3]}_{1})\n",
    "$$\n",
    "\n",
    "Again with random weights and bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: compute a3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have built your own neural network, impressive, right?\n",
    "\n",
    "You now know how a neural network can compute a value (for regression or classification) just by having units and layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optional: vectorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This part is optional and a bit more complicated.\n",
    "\n",
    "You might have noticed that we made a lot of computations that could be vectorized. Meaning, instead of computing separately `a11`, `a12`, `a13`, `a14`, we could have compute directly `a1`. It works for other layers too. We will do it that way now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will keep our input vector `X`, and define a weight matrix `W1` and a bias vector `b1` randomly. And then, having those three variables, compute `a1` in just one line of code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: compute a1 in one line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It gets easier, right? Now that you got it, compute `a2` and finally `a3` in just a couple of lines of code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: compute a2 and a3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This process is called vectorization, and helps a lot in computing matrix calculations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you still have time, you can try to define a function that takes as parameters an input vector `X`, the number of layers `L` and the units per layer `units` and returns the output of the associated neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optional: generalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have more time, try to generalize what you did: build a function (or a class!) that computes the forward propagation, with the number of input features, layers and units per layers as **parameters** of the function."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
